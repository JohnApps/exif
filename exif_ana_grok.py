# exif_ana_grok.py
#
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Generate by Grok from the original generated by CoPilot
#
"""
exif_ana.py
Analyze JPGs referenced in a DuckDB EXIF table, store per-photo analysis and monthly summary,
and generate graphs for camera model, aperture, shutter speed, ISO (raw + normalized stops),
and exposure value.

Usage:
    python exif_ana.py --db exif_csv.db --exif-table exif --image-root /path/to/photos --overwrite

Author: Copilot (updated with improvements)
"""

import argparse
import json
import logging
import math
import os
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import duckdb
import pandas as pd
from tqdm import tqdm

import torch
from PIL import Image, UnidentifiedImageError
import matplotlib.pyplot as plt
from torchvision import models


# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


# --------------------------- CLI --------------------------- 

def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Analyze JPGs in DuckDB EXIF table.")
    parser.add_argument("--db", default="exif_csv.db", help="DuckDB database path.")
    parser.add_argument("--exif-table", default="exif", help="EXIF table name.")
    parser.add_argument("--analysis-table", default="analysis", help="Output analysis table.")
    parser.add_argument("--summary-table", default="summary", help="Output summary table.")
    parser.add_argument("--filename-col", default="FileName", help="Column with file name/path.")
    parser.add_argument("--datetime-col", default="ModifyDate", help="Column with date/time.")
    parser.add_argument("--aperture-col", default="Aperture", help="Aperture column (F-number).")
    parser.add_argument("--shutter-col", default="ShutterSpeed", help="Shutter speed column (seconds or fraction).")
    parser.add_argument("--iso-col", default="ISOSetting", help="ISO sensitivity column.")
    parser.add_argument("--model-col", default="Model", help="Camera model column.")
    parser.add_argument("--image-root", default="", help="Root folder to prepend to FileName if relative.")
    parser.add_argument("--limit", type=int, default=None, help="Limit number of images to analyze.")
    parser.add_argument("--overwrite", action="store_true", help="Overwrite output tables (replaces CREATE OR REPLACE).")
    parser.add_argument("--graphs-dir", default="graphs", help="Directory to save graphs.")
    parser.add_argument("--device", default=None, choices=["cpu", "cuda"], help="Force device; default auto.")
    parser.add_argument("--topk", type=int, default=5, help="Top-K labels for description/categories.")
    parser.add_argument("--dry-run", action="store_true", help="Extract metadata only, skip image analysis/inference.")
    return parser.parse_args()


# --------------------------- Utilities --------------------------- 

def setup_device(choice: Optional[str]) -> torch.device:
    if choice == "cpu":
        return torch.device("cpu")
    if choice == "cuda":
        if torch.cuda.is_available():
            return torch.device("cuda")
        else:
            logging.warning("CUDA requested but not available, falling back to CPU.")
            return torch.device("cpu")
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")


def normalize_path(name: str, root: str = "") -> str:
    name = str(name).strip()
    p = Path(name).expanduser()
    if p.is_absolute():
        return str(p.resolve())
    else:
        root_p = Path(root).expanduser().resolve() if root else Path.cwd().resolve()
        return str(root_p / p)


def is_jpg(path: str) -> bool:
    return str(path).lower().endswith((".jpg", ".jpeg"))


def safe_parse_datetime(val: object) -> Optional[datetime]:
    if val is None or (isinstance(val, float) and pd.isna(val)):
        return None
    s = str(val).strip()
    fmts = ["%Y:%m:%d %H:%M:%S", "%Y-%m-%d %H:%M:%S", "%Y-%m-%dT%H:%M:%S", "%Y-%m-%d", "%Y:%m:%d"]
    for f in fmts:
        try:
            return datetime.strptime(s, f)
        except ValueError:
            continue
    return None


def extract_aperture(val: object) -> Optional[float]:
    if val is None or (isinstance(val, float) and pd.isna(val)):
        return None
    try:
        return float(val)
    except (ValueError, TypeError):
        m = re.search(r"(\d+(?:\.\d+)?)", str(val))
        return float(m.group(1)) if m else None


def extract_shutter(val: object) -> Optional[float]:
    if val is None or (isinstance(val, float) and pd.isna(val)):
        return None
    s = str(val).strip().lower()
    # Try fraction (support decimals)
    frac_match = re.match(r"^(\d+(?:\.\d+)?)\s*/\s*(\d+(?:\.\d+)?)$", s)
    if frac_match:
        num, den = map(float, frac_match.groups())
        return num / den if den != 0 else None
    # Try direct float (for decimals like 0.0167)
    try:
        return float(s)
    except (ValueError, TypeError):
        return None


def shutter_display(v: Optional[float]) -> Optional[str]:
    if v is None or v <= 0:
        return None
    if v >= 1:
        return f"{v:.3f} s"
    denom = max(1, round(1 / v))
    return f"1/{denom} s"


def normalize_iso(iso_val: Optional[float]) -> Optional[int]:
    if iso_val is None or pd.isna(iso_val) or iso_val <= 0:
        return None
    stops = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800, 25600, 51200]
    closest = min(stops, key=lambda s: abs(math.log2(iso_val / s)))
    return closest


def build_label_to_category() -> Dict[str, str]:
    return {
        # animals
        "dog": "animals", "cat": "animals", "bird": "animals", "horse": "animals",
        "cow": "animals", "sheep": "animals", "lion": "animals", "tiger": "animals",
        "fish": "animals", "snake": "animals",
        # vehicles
        "car": "vehicles", "sports car": "vehicles", "convertible": "vehicles",
        "jeep": "vehicles", "ship": "vehicles", "airliner": "vehicles", "airplane": "vehicles",
        "bicycle": "vehicles", "motorcycle": "vehicles", "bus": "vehicles", "train": "vehicles",
        "helicopter": "vehicles",
        # architecture / urban
        "building": "architecture", "church": "architecture", "castle": "architecture",
        "monastery": "architecture", "mosque": "architecture", "tower": "architecture",
        "bridge": "architecture", "house": "architecture", "skyscraper": "architecture",
        "stadium": "architecture", "street": "urban", "city": "urban",
        # nature
        "park": "nature", "forest": "nature", "valley": "nature", "mountain": "nature",
        "lake": "nature", "sea": "nature", "ocean": "nature", "beach": "nature",
        "tree": "nature", "flower": "nature", "river": "nature", "snow": "nature", "sun": "nature",
        # people
        "person": "people", "woman": "people", "man": "people", "child": "people",
        "baby": "people", "girl": "people", "boy": "people",
        # objects
        "camera": "objects", "laptop": "objects", "cellular telephone": "objects", 
        "smartphone": "objects", "phone": "objects", "book": "objects", 
        "bottle": "objects", "chair": "objects",
        # food
        "food": "food", "pizza": "food", "hamburger": "food", "coffee": "food",
    }


def prepare_model(device: torch.device):
    try:
        weights = models.ResNet50_Weights.DEFAULT
        model = models.resnet50(weights=weights)
        model.eval()
        model.to(device)
        preprocess = weights.transforms()
        idx_to_label = weights.meta["categories"]
        return model, preprocess, idx_to_label
    except Exception as e:
        logging.error(f"Failed to load model: {e}")
        sys.exit(1)


def load_image_safely(path: str) -> Optional[Image.Image]:
    try:
        with Image.open(path) as im:
            return im.convert("RGB")
    except (FileNotFoundError, UnidentifiedImageError, OSError) as e:
        logging.debug(f"Image load error for {path}: {e}")
        return None


def describe_from_labels(labels: List[str]) -> str:
    if not labels:
        return "No recognizable content."
    if len(labels) == 1:
        return f"A photo of {labels[0]}."
    return f"A photo of {', '.join(labels[:-1])}, and {labels[-1]}."


def infer_categories(labels: List[str], category_map: Dict[str, str]) -> List[str]:
    cats = []
    for l in labels:
        low = l.lower()
        if low in category_map:
            cats.append(category_map[low])
            continue
        for k, v in category_map.items():
            if k in low:
                cats.append(v)
                break
    # Dedupe
    out = list(dict.fromkeys(cats))  # preserves order
    return out or ["uncategorized"]


# --------------------------- Main --------------------------- 

def main():
    args = parse_args()
    device = setup_device(args.device)
    graphs_dir = Path(args.graphs_dir)
    graphs_dir.mkdir(exist_ok=True)

    # Connect DuckDB and load data
    conn = duckdb.connect(args.db)
    exif_df = conn.execute(f"SELECT * FROM {args.exif_table}").fetch_df()

    # Build full paths; filter JPGs
    full_paths = exif_df[args.filename_col].astype(str).apply(lambda x: normalize_path(x, args.image_root))
    mask = full_paths.apply(is_jpg)
    work_df = exif_df.loc[mask].copy()
    work_df["__path__"] = full_paths[mask]

    if args.limit is not None:
        work_df = work_df.iloc[:args.limit].copy()

    if work_df.empty:
        logging.info("No JPG files found to analyze.")
        return

    # Prepare model
    logging.info(f"Loading model on device: {device}")
    model, preprocess, idx_to_label = prepare_model(device)
    category_map = build_label_to_category()

    # Process metadata and prepare for inference
    records: List[Dict] = []
    tensors_to_process: List[torch.Tensor] = []
    indices_to_update: List[int] = []
    missing_files = 0

    for _, row in tqdm(work_df.iterrows(), total=len(work_df), desc="Extracting metadata and loading images"):
        filepath = row["__path__"]
        exists = Path(filepath).exists()

        if not exists:
            missing_files += 1
            logging.debug(f"Missing file: {filepath}")

        dt = safe_parse_datetime(row.get(args.datetime_col))
        year = dt.year if dt else None
        month = dt.month if dt else None

        aperture = extract_aperture(row.get(args.aperture_col))
        shutter_seconds = extract_shutter(row.get(args.shutter_col))
        shutter_disp = shutter_display(shutter_seconds)

        iso_raw_val = row.get(args.iso_col)
        iso_clean = pd.to_numeric(iso_raw_val, errors="coerce")
        iso_norm = normalize_iso(iso_clean)

        model_name = row.get(args.model_col)

        # Compute exposure value
        ev_val = None
        if (aperture and shutter_seconds and shutter_seconds > 0 and 
            iso_clean and iso_clean > 0 and not pd.isna(iso_clean)):
            try:
                ev = math.log2(aperture**2 / shutter_seconds) - math.log2(iso_clean / 100)
                ev_val = round(ev, 2)
            except (ValueError, OverflowError):
                pass

        base_record = {
            "filename": filepath,
            "exists": exists,
            "labels_topk": json.dumps([]),
            "categories": json.dumps(["uncategorized"]),
            "description": "No analysis performed.",
            "year": year,
            "month": month,
            "camera_model": model_name,
            "aperture": aperture,
            "shutter_seconds": shutter_seconds,
            "shutter_display": shutter_disp,
            "iso": iso_clean,
            "iso_normalized": iso_norm,
            "exposure_value": ev_val,
        }
        records.append(base_record)

        if exists:
            img = load_image_safely(filepath)
            if img is not None:
                tensor = preprocess(img).unsqueeze(0)
                tensors_to_process.append(tensor)
                indices_to_update.append(len(records) - 1)
            else:
                logging.warning(f"Could not load image: {filepath}")

    analysis_df = pd.DataFrame(records)

    # Run batched inference if not dry-run
    if not args.dry_run and tensors_to_process:
        logging.info(f"Running batched inference on {len(tensors_to_process)} images (batch size 32)")
        batch_size = 32
        with torch.no_grad():
            for start in range(0, len(tensors_to_process), batch_size):
                end = min(start + batch_size, len(tensors_to_process))
                batch = torch.stack(tensors_to_process[start:end]).to(device)
                logits = model(batch)
                probs = torch.softmax(logits, dim=1)
                top_probs, top_inds = torch.topk(probs, args.topk, dim=1)
                for b in range(batch.shape[0]):
                    local_idx = start + b
                    rec_idx = indices_to_update[local_idx]
                    labels = []
                    for j in range(args.topk):
                        label_name = idx_to_label[int(top_inds[b, j])]
                        conf = float(top_probs[b, j])
                        labels.append({"label": label_name, "confidence": conf})
                    records[rec_idx]["labels_topk"] = json.dumps(labels)
                    label_names = [l["label"] for l in labels]
                    records[rec_idx]["description"] = describe_from_labels(label_names)
                    cats = infer_categories(label_names, category_map)
                    records[rec_idx]["categories"] = json.dumps(cats)
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        # Refresh df after updates
        analysis_df = pd.DataFrame(records)
        logging.info("Inference completed.")
    else:
        logging.info("Skipping inference (dry-run mode or no valid images).")

    # Write analysis table
    if args.overwrite:
        conn.execute(f"DROP TABLE IF EXISTS {args.analysis_table}")
        conn.execute(f"CREATE TABLE {args.analysis_table} AS SELECT * FROM analysis_df")
    else:
        try:
            conn.execute(f"INSERT INTO {args.analysis_table} SELECT * FROM analysis_df")
        except Exception:
            conn.execute(f"CREATE TABLE {args.analysis_table} AS SELECT * FROM analysis_df")
    logging.info(f"Wrote {len(analysis_df)} rows to '{args.analysis_table}'.")

    # Build and write summary table
    summary = (
        analysis_df.dropna(subset=["year", "month"])
        .groupby(["year", "month"])
        .agg(
            count=("filename", "size"),
            avg_aperture=("aperture", "mean"),
            avg_shutter=("shutter_seconds", "mean"),
            avg_iso=("iso", "mean"),
            avg_ev=("exposure_value", "mean"),
        )
        .round(2)
        .reset_index()
        .sort_values(["year", "month"])
    )
    if args.overwrite:
        conn.execute(f"DROP TABLE IF EXISTS {args.summary_table}")
        conn.execute(f"CREATE TABLE {args.summary_table} AS SELECT * FROM summary")
    else:
        try:
            conn.execute(f"INSERT INTO {args.summary_table} SELECT * FROM summary")
        except Exception:
            conn.execute(f"CREATE TABLE {args.summary_table} AS SELECT * FROM summary")
    logging.info(f"Wrote {len(summary)} rows to '{args.summary_table}'.")

    # Generate graphs
    saved_graphs = []

    # Camera model counts
    cm = analysis_df.dropna(subset=["camera_model"])
    if not cm.empty:
        plt.figure(figsize=(10, 6))
        cm["camera_model"].value_counts().sort_values(ascending=False).plot(kind="bar")
        plt.title("Photos by camera model")
        plt.xlabel("Camera model")
        plt.ylabel("Count")
        plt.xticks(rotation=45, ha="right")
        plt.tight_layout()
        cm_path = graphs_dir / "camera_model_counts.png"
        plt.savefig(cm_path)
        plt.close()
        saved_graphs.append(cm_path)

    # Aperture distribution
    ap = analysis_df.dropna(subset=["aperture"])
    if not ap.empty:
        plt.figure(figsize=(10, 6))
        bins = [1.0, 1.4, 2.0, 2.8, 4.0, 5.6, 8.0, 11.0, 16.0, 22.0, 32.0]
        plt.hist(ap["aperture"], bins=bins, edgecolor="black")
        plt.title("Aperture distribution (F-number)")
        plt.xlabel("F-number")
        plt.ylabel("Count")
        plt.tight_layout()
        ap_path = graphs_dir / "aperture_distribution.png"
        plt.savefig(ap_path)
        plt.close()
        saved_graphs.append(ap_path)

    # Shutter speed distribution (log scale)
    ss = analysis_df.dropna(subset=["shutter_seconds"])
    if not ss.empty and (ss["shutter_seconds"] > 0).all():
        plt.figure(figsize=(10, 6))
        plt.hist(ss["shutter_seconds"], bins=50, edgecolor="black")
        plt.xscale("log")
        plt.title("Shutter speed distribution (seconds, log scale)")
        plt.xlabel("Seconds (log scale)")
        plt.ylabel("Count")
        plt.tight_layout()
        ss_path = graphs_dir / "shutter_speed_distribution.png"
        plt.savefig(ss_path)
        plt.close()
        saved_graphs.append(ss_path)

    # ISO raw distribution
    iso_raw = analysis_df.dropna(subset=["iso"])
    if not iso_raw.empty:
        plt.figure(figsize=(10, 6))
        plt.hist(iso_raw["iso"].astype(float), bins=30, edgecolor="black")
        plt.title("ISO setting distribution (raw)")
        plt.xlabel("ISO value")
        plt.ylabel("Count")
        plt.tight_layout()
        iso_raw_path = graphs_dir / "iso_distribution_raw.png"
        plt.savefig(iso_raw_path)
        plt.close()
        saved_graphs.append(iso_raw_path)

    # ISO normalized stops
    iso_norm_df = analysis_df.dropna(subset=["iso_normalized"])
    if not iso_norm_df.empty:
        plt.figure(figsize=(10, 6))
        iso_norm_df["iso_normalized"].value_counts().sort_index().plot(kind="bar")
        plt.title("ISO setting distribution (normalized stops)")
        plt.xlabel("ISO value (standard stops)")
        plt.ylabel("Count")
        plt.tight_layout()
        iso_norm_path = graphs_dir / "iso_distribution_normalized.png"
        plt.savefig(iso_norm_path)
        plt.close()
        saved_graphs.append(iso_norm_path)

    # Exposure Value distribution
    ev_df = analysis_df.dropna(subset=["exposure_value"])
    if not ev_df.empty:
        plt.figure(figsize=(10, 6))
        plt.hist(ev_df["exposure_value"], bins=20, edgecolor="black")
        plt.title("Exposure Value (EV) distribution")
        plt.xlabel("EV")
        plt.ylabel("Count")
        plt.tight_layout()
        ev_path = graphs_dir / "exposure_value_distribution.png"
        plt.savefig(ev_path)
        plt.close()
        saved_graphs.append(ev_path)

    if saved_graphs:
        logging.info("Saved graphs:")
        for p in saved_graphs:
            logging.info(f" - {p}")
    else:
        logging.info("No graphs generated (insufficient data).")

    # Final notes
    missing_msg = f"{missing_files} files were missing" if missing_files > 0 else "all files found"
    logging.info(f"Completed analysis; {missing_msg}.")
    logging.info("Done.")


if __name__ == "__main__":
    main()